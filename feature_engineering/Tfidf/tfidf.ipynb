{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35eacc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,os\n",
    "sys.path.append( os.path.join(\"..\",\"..\",))\n",
    "from UtilityFunctions import CommonHelpers, PreprocessHelpers, FeatureEngineering\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24c65c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "PREPROCESSED_STORE_LOC = os.path.join(\"..\", \"..\", \"..\", \"pickle_files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e420cd8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_books = CommonHelpers.load_pickle(os.path.join(PREPROCESSED_STORE_LOC,\"books_1635_preprocessed.pickle\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7494f949",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1600"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_books)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44981abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "book_names = CommonHelpers.load_pickle(os.path.join(PREPROCESSED_STORE_LOC,\"names_1635.pickle\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba76cda6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1600"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(book_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c8e344f",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_books = [' '.join(book) for book in all_books]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00cdaee2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1600, 10000)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(analyzer = 'word', token_pattern = r'\\w{1,}', ngram_range=(1, 2), stop_words='english', max_features=10000)\n",
    "features = tfidf.fit_transform(combined_books).toarray()\n",
    "# labels = df.category_id\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c0c72fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re \n",
    "# catalog = pd.read_csv('pg_catalog.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "80726e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_number_id(file_name):\n",
    "    regex = r\"([a-z_A-Z]+)(\\d+)\"\n",
    "    match = re.search(regex, file_name)\n",
    "    if match!=None:\n",
    "        return match.group(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0fd53b4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data\n",
      "Loading data complete\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading data\")\n",
    "df = pd.read_csv(\"../../data/pg_catalog.csv\")\n",
    "df[\"category\"] = df[\"LoCC\"].str[:1]\n",
    "category_list_train = [int(get_number_id(each)) for each in book_names]\n",
    "selected_books = df[df[\"Text#\"].isin(category_list_train)]\n",
    "categories = selected_books.iloc[:,9].tolist()\n",
    "titles = selected_books.iloc[:,3].tolist()\n",
    "print(\"Loading data complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9fb20f96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_categories = selected_books.iloc[:,9].unique()\n",
    "type(unique_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4226e9a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. J :\n",
      "\t# Unigrams :\n",
      "\t. sabbath\n",
      "\t. paraguay\n",
      "\t. maori\n",
      "\t. armour\n",
      "\t. therapi\n",
      "\t# Bigrams :\n",
      "\t. edit cr\n",
      "\t. cross examin\n",
      "\t. cr vo\n",
      "\t. book plate\n",
      "\t. miss nightingal\n",
      "2. F :\n",
      "\t# Unigrams :\n",
      "\t. guatemala\n",
      "\t. alto\n",
      "\t. singapor\n",
      "\t. banana\n",
      "\t. gram\n",
      "\t# Bigrams :\n",
      "\t. woman suffrag\n",
      "\t. suffrag associ\n",
      "\t. book plate\n",
      "\t. n g\n",
      "\t. uncut edg\n",
      "3. G :\n",
      "\t# Unigrams :\n",
      "\t. citat\n",
      "\t. memo\n",
      "\t. gallatin\n",
      "\t. aeroplan\n",
      "\t. mitso\n",
      "\t# Bigrams :\n",
      "\t. air forc\n",
      "\t. biblioth que\n",
      "\t. vo cloth\n",
      "\t. mr gallatin\n",
      "\t. sir mose\n",
      "4. P :\n",
      "\t# Unigrams :\n",
      "\t. concret\n",
      "\t. pg\n",
      "\t. gambia\n",
      "\t. mm\n",
      "\t. fiber\n",
      "\t# Bigrams :\n",
      "\t. illustr plate\n",
      "\t. teaspoon salt\n",
      "\t. crown vo\n",
      "\t. n c\n",
      "\t. z n\n",
      "5. U :\n",
      "\t# Unigrams :\n",
      "\t. ln\n",
      "\t. arabella\n",
      "\t. jeg\n",
      "\t. duerer\n",
      "\t. nnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnn\n",
      "\t# Bigrams :\n",
      "\t. sierra leon\n",
      "\t. continent shelf\n",
      "\t. thirteenth centuri\n",
      "\t. west india\n",
      "\t. nnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnn nnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnn\n",
      "6. Q :\n",
      "\t# Unigrams :\n",
      "\t. meteor\n",
      "\t. horton\n",
      "\t. rodney\n",
      "\t. canyon\n",
      "\t. hacienda\n",
      "\t# Bigrams :\n",
      "\t. coat arm\n",
      "\t. jul r\n",
      "\t. c sar\n",
      "\t. w w\n",
      "\t. lord byron\n",
      "7. K :\n",
      "\t# Unigrams :\n",
      "\t. mujer\n",
      "\t. ami\n",
      "\t. beecher\n",
      "\t. thaw\n",
      "\t. schacht\n",
      "\t# Bigrams :\n",
      "\t. da die\n",
      "\t. pepper salt\n",
      "\t. justic jackson\n",
      "\t. la sall\n",
      "\t. mr beecher\n",
      "8. T :\n",
      "\t# Unigrams :\n",
      "\t. alley\n",
      "\t. haue\n",
      "\t. tuberculosi\n",
      "\t. toledo\n",
      "\t. vitamin\n",
      "\t# Bigrams :\n",
      "\t. democrat parti\n",
      "\t. free state\n",
      "\t. republican parti\n",
      "\t. r jul\n",
      "\t. deg deg\n",
      "9. E :\n",
      "\t# Unigrams :\n",
      "\t. handel\n",
      "\t. tha\n",
      "\t. baha\n",
      "\t. thei\n",
      "\t. wergeld\n",
      "\t# Bigrams :\n",
      "\t. tout le\n",
      "\t. le mond\n",
      "\t. th regiment\n",
      "\t. senat unit\n",
      "\t. ed p\n",
      "10. L :\n",
      "\t# Unigrams :\n",
      "\t. odour\n",
      "\t. ewe\n",
      "\t. sapper\n",
      "\t. larri\n",
      "\t. liberia\n",
      "\t# Bigrams :\n",
      "\t. light hous\n",
      "\t. vo pp\n",
      "\t. justic jackson\n",
      "\t. g ring\n",
      "\t. bell rock\n",
      "11. H :\n",
      "\t# Unigrams :\n",
      "\t. lifeboat\n",
      "\t. pferd\n",
      "\t. hawk\n",
      "\t. gipsi\n",
      "\t. brahm\n",
      "\t# Bigrams :\n",
      "\t. feb r\n",
      "\t. apr r\n",
      "\t. marin corp\n",
      "\t. r c\n",
      "\t. jan r\n",
      "12. C :\n",
      "\t# Unigrams :\n",
      "\t. hemp\n",
      "\t. armenia\n",
      "\t. pascal\n",
      "\t. andi\n",
      "\t. truss\n",
      "\t# Bigrams :\n",
      "\t. crown vo\n",
      "\t. west point\n",
      "\t. g g\n",
      "\t. rev mr\n",
      "\t. r r\n",
      "13. R :\n",
      "\t# Unigrams :\n",
      "\t. iceberg\n",
      "\t. burr\n",
      "\t. jem\n",
      "\t. mushroom\n",
      "\t. kaj\n",
      "\t# Bigrams :\n",
      "\t. pave runway\n",
      "\t. machin gun\n",
      "\t. p l\n",
      "\t. small letter\n",
      "\t. greek small\n",
      "14. B :\n",
      "\t# Unigrams :\n",
      "\t. marjori\n",
      "\t. terri\n",
      "\t. fiji\n",
      "\t. ya\n",
      "\t. brodi\n",
      "\t# Bigrams :\n",
      "\t. apr r\n",
      "\t. feb r\n",
      "\t. n w\n",
      "\t. mar r\n",
      "\t. member state\n",
      "15. D :\n",
      "\t# Unigrams :\n",
      "\t. cypru\n",
      "\t. snell\n",
      "\t. mackenzi\n",
      "\t. allah\n",
      "\t. beric\n",
      "\t# Bigrams :\n",
      "\t. democrat republ\n",
      "\t. cr vo\n",
      "\t. edit cr\n",
      "\t. life boat\n",
      "\t. lord john\n",
      "16. N :\n",
      "\t# Unigrams :\n",
      "\t. mesoblast\n",
      "\t. km\n",
      "\t. overview\n",
      "\t. larva\n",
      "\t. ski\n",
      "\t# Bigrams :\n",
      "\t. que il\n",
      "\t. decemb est\n",
      "\t. est countri\n",
      "\t. countri comparison\n",
      "\t. comparison world\n",
      "17. A :\n",
      "\t# Unigrams :\n",
      "\t. dosag\n",
      "\t. marion\n",
      "\t. torpedo\n",
      "\t. hutton\n",
      "\t. submarin\n",
      "\t# Bigrams :\n",
      "\t. action use\n",
      "\t. ffel voll\n",
      "\t. n f\n",
      "\t. u p\n",
      "\t. jimmi dale\n",
      "18. M :\n",
      "\t# Unigrams :\n",
      "\t. glue\n",
      "\t. collat\n",
      "\t. newfoundland\n",
      "\t. comeniu\n",
      "\t. neurosyphili\n",
      "\t# Bigrams :\n",
      "\t. attorney gener\n",
      "\t. gener assembl\n",
      "\t. mr william\n",
      "\t. london print\n",
      "\t. quantiti person\n",
      "19. S :\n",
      "\t# Unigrams :\n",
      "\t. lighthous\n",
      "\t. milford\n",
      "\t. cong\n",
      "\t. pepi\n",
      "\t. ronald\n",
      "\t# Bigrams :\n",
      "\t. le petit\n",
      "\t. la r\n",
      "\t. public librari\n",
      "\t. french armi\n",
      "\t. ed p\n",
      "20. Z :\n",
      "\t# Unigrams :\n",
      "\t. vs\n",
      "\t. crochet\n",
      "\t. caxton\n",
      "\t. soveraign\n",
      "\t. peanut\n",
      "\t# Bigrams :\n",
      "\t. vo cloth\n",
      "\t. http www\n",
      "\t. r h\n",
      "\t. illustr illustr\n",
      "\t. th infantri\n",
      "21. V :\n",
      "\t# Unigrams :\n",
      "\t. augusta\n",
      "\t. hester\n",
      "\t. lama\n",
      "\t. laura\n",
      "\t. rembrandt\n",
      "\t# Bigrams :\n",
      "\t. c h\n",
      "\t. c e\n",
      "\t. mr madison\n",
      "\t. birth rate\n",
      "\t. miss beal\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import chi2\n",
    "N = 5\n",
    "Number = 1\n",
    "for category in unique_categories:\n",
    "    features_chi2 = chi2(features, selected_books['category'] == category)\n",
    "    indices = np.argsort(features_chi2[0])\n",
    "    feature_names = np.array(tfidf.get_feature_names_out())[indices]\n",
    "    unigrams = [v for v in feature_names if len(v.split(' ')) == 1]\n",
    "    bigrams = [v for v in feature_names if len(v.split(' ')) == 2]\n",
    "    print(\"{}. {} :\".format(Number,category))\n",
    "    print(\"\\t# Unigrams :\\n\\t. {}\".format('\\n\\t. '.join(unigrams[-N:])))\n",
    "    print(\"\\t# Bigrams :\\n\\t. {}\".format('\\n\\t. '.join(bigrams[-N:])))\n",
    "    Number += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
