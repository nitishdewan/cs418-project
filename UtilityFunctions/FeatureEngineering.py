import numpy as np
import pandas as pd
from scipy import spatial
from sklearn import preprocessing

def make_feature_vector(words, model, num_features):
    """
    Average the word vectors for a set of words
    """
    feature_vec = np.zeros((num_features,),dtype="float32")  # pre-initialize (for speed)
    n_words = 0
    index2word_set = set(model.index_to_key)  # words known to the model

    for word in words:
        if word in index2word_set: 
            n_words = n_words + 1
            feature_vec = np.add(feature_vec,model[word])
    try:
        feature_vec = np.divide(feature_vec, n_words)
    except:
        print("Divide by zero error for ",words[:20])
    return feature_vec


def get_avg_feature_vectors(books, model, num_features):
    """
    Calculate average feature vectors for all books
    """
    counter = 0
    feature_vectors = np.zeros((len(books),num_features), dtype='float32')  # pre-initialize (for speed)
    
    for review in books:
        feature_vectors[counter] = make_feature_vector(review, model, num_features)
        counter = counter + 1
    
    return feature_vectors

def get_trained_vectors(books,model):
    '''
    Get feature vectors of all books generated by training Word2Vec
    '''
    list_of_words = books
    model_w2v = model(list_of_words[:], min_count = 1, window = 5)
    model_w2v.train(list_of_words[:], total_examples=len(list_of_words[:]), epochs=2)
    wordvec_dict = dict({})
    for idx, key in enumerate(model_w2v.wv.index_to_key):
        wordvec_dict[key] = model_w2v.wv[key]
    cnt = 0
    book_vec = {} #dictionary of book vectors
    cnt_arr = []
    for book in list_of_words[:]:
        if len(book) == 0:
            book_vec[cnt] = wordvec_dict["note"]
            cnt += 1
        else:
            for word in book:
                if cnt not in book_vec:
                    book_vec[cnt] = wordvec_dict[word]
                else:
                    book_vec[cnt] = (book_vec[cnt] + wordvec_dict[word])
            cnt += 1
    book_vec = list(book_vec.values())
    print(len(book_vec), type(book_vec))
    scaler = preprocessing.StandardScaler().fit(book_vec)
    book_vec = scaler.transform(book_vec)
    return book_vec


def get_document_similarity(vector1,vector2):
    return 1 - spatial.distance.cosine(vector1, vector2)